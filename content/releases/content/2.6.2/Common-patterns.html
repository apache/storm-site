<p>This page lists a variety of common patterns in Storm topologies.</p>

<ol>
  <li>Batching</li>
  <li>BasicBolt</li>
  <li>In-memory caching + fields grouping combo</li>
  <li>Streaming top N</li>
  <li>TimeCacheMap for efficiently keeping a cache of things that have been recently updated</li>
  <li>CoordinatedBolt and KeyedFairBolt for Distributed RPC</li>
</ol>

<h3 id="batching">Batching</h3>

<p>Oftentimes for efficiency reasons or otherwise, you want to process a group of tuples in batch rather than individually. For example, you may want to batch updates to a database or do a streaming aggregation of some sort.</p>

<p>If you want reliability in your data processing, the right way to do this is to hold on to tuples in an instance variable while the bolt waits to do the batching. Once you do the batch operation, you then ack all the tuples you were holding onto.</p>

<p>If the bolt emits tuples, then you may want to use multi-anchoring to ensure reliability. It all depends on the specific application. See <a href="Guaranteeing-message-processing.html">Guaranteeing message processing</a> for more details on how reliability works.</p>

<h3 id="basicbolt">BasicBolt</h3>
<p>Many bolts follow a similar pattern of reading an input tuple, emitting zero or more tuples based on that input tuple, and then acking that input tuple immediately at the end of the execute method. Bolts that match this pattern are things like functions and filters. This is such a common pattern that Storm exposes an interface called <a href="javadocs/org/apache/storm/topology/IBasicBolt.html">IBasicBolt</a> that automates this pattern for you. See <a href="Guaranteeing-message-processing.html">Guaranteeing message processing</a> for more information.</p>

<h3 id="in-memory-caching--fields-grouping-combo">In-memory caching + fields grouping combo</h3>

<p>It’s common to keep caches in-memory in Storm bolts. Caching becomes particularly powerful when you combine it with a fields grouping. For example, suppose you have a bolt that expands short URLs (like bit.ly, t.co, etc.) into long URLs. You can increase performance by keeping an LRU cache of short URL to long URL expansions to avoid doing the same HTTP requests over and over. Suppose component “urls” emits short URLS, and component “expand” expands short URLs into long URLs and keeps a cache internally. Consider the difference between the two following snippets of code:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">builder</span><span class="o">.</span><span class="na">setBolt</span><span class="o">(</span><span class="s">"expand"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">ExpandUrl</span><span class="o">(),</span> <span class="n">parallelism</span><span class="o">)</span>
  <span class="o">.</span><span class="na">shuffleGrouping</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>
</code></pre></div></div>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">builder</span><span class="o">.</span><span class="na">setBolt</span><span class="o">(</span><span class="s">"expand"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">ExpandUrl</span><span class="o">(),</span> <span class="n">parallelism</span><span class="o">)</span>
  <span class="o">.</span><span class="na">fieldsGrouping</span><span class="o">(</span><span class="s">"urls"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">Fields</span><span class="o">(</span><span class="s">"url"</span><span class="o">));</span>
</code></pre></div></div>

<p>The second approach will have vastly more effective caches since the same URL will always go to the same task. This avoids having duplication across any of the caches in the tasks and makes it much more likely that a short URL will hit the cache.</p>

<h3 id="streaming-top-n">Streaming top N</h3>

<p>A common continuous computation done on Storm is a “streaming top N” of some sort. Suppose you have a bolt that emits tuples of the form [“value”, “count”] and you want a bolt that emits the top N tuples based on the count. The simplest way to do this is to have a bolt that does a global grouping on the stream and maintains a list in memory of the top N items.</p>

<p>This approach obviously doesn’t scale to large streams since the entire stream has to go through one task. A better way to do the computation is to do many top N’s in parallel across partitions of the stream, and then merge those top N’s together to get the global top N. The pattern looks like this:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">builder</span><span class="o">.</span><span class="na">setBolt</span><span class="o">(</span><span class="s">"rank"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">RankObjects</span><span class="o">(),</span> <span class="n">parallelism</span><span class="o">)</span>
  <span class="o">.</span><span class="na">fieldsGrouping</span><span class="o">(</span><span class="s">"objects"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">Fields</span><span class="o">(</span><span class="s">"value"</span><span class="o">));</span>
<span class="n">builder</span><span class="o">.</span><span class="na">setBolt</span><span class="o">(</span><span class="s">"merge"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">MergeObjects</span><span class="o">())</span>
  <span class="o">.</span><span class="na">globalGrouping</span><span class="o">(</span><span class="s">"rank"</span><span class="o">);</span>
</code></pre></div></div>

<p>This pattern works because of the fields grouping done by the first bolt which gives the partitioning you need for this to be semantically correct. You can see an example of this pattern in storm-starter <a href="/examples/storm-starter/src/jvm/org/apache/storm/starter/RollingTopWords.java">here</a>.</p>

<p>If however, you have a known skew in the data being processed it can be advantageous to use partialKeyGrouping instead of fieldsGrouping.  This will distribute the load for each key between two downstream bolts instead of a single one.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">builder</span><span class="o">.</span><span class="na">setBolt</span><span class="o">(</span><span class="s">"count"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">CountObjects</span><span class="o">(),</span> <span class="n">parallelism</span><span class="o">)</span>
  <span class="o">.</span><span class="na">partialKeyGrouping</span><span class="o">(</span><span class="s">"objects"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">Fields</span><span class="o">(</span><span class="s">"value"</span><span class="o">));</span>
<span class="n">builder</span><span class="o">.</span><span class="na">setBolt</span><span class="o">(</span><span class="s">"rank"</span> <span class="k">new</span> <span class="nc">AggregateCountsAndRank</span><span class="o">(),</span> <span class="n">parallelism</span><span class="o">)</span>
  <span class="o">.</span><span class="na">fieldsGrouping</span><span class="o">(</span><span class="s">"count"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">Fields</span><span class="o">(</span><span class="s">"key"</span><span class="o">))</span>
<span class="n">builder</span><span class="o">.</span><span class="na">setBolt</span><span class="o">(</span><span class="s">"merge"</span><span class="o">,</span> <span class="k">new</span> <span class="nc">MergeRanksObjects</span><span class="o">())</span>
  <span class="o">.</span><span class="na">globalGrouping</span><span class="o">(</span><span class="s">"rank"</span><span class="o">);</span>
</code></pre></div></div>

<p>The topology needs an extra layer of processing to aggregate the partial counts from the upstream bolts but this only processes aggregated values now so the bolt is not subject to the load caused by the skewed data. You can see an example of this pattern in storm-starter <a href="/examples/storm-starter/src/jvm/org/apache/storm/starter/SkewedRollingTopWords.java">here</a>.</p>

<h3 id="timecachemap-for-efficiently-keeping-a-cache-of-things-that-have-been-recently-updated">TimeCacheMap for efficiently keeping a cache of things that have been recently updated</h3>

<p>You sometimes want to keep a cache in memory of items that have been recently “active” and have items that have been inactive for some time automatically expire. <a href="javadocs/org/apache/storm/utils/TimeCacheMap.html">TimeCacheMap</a> is an efficient data structure for doing this and provides hooks so you can insert callbacks whenever an item is expired.</p>

<h3 id="coordinatedbolt-and-keyedfairbolt-for-distributed-rpc">CoordinatedBolt and KeyedFairBolt for Distributed RPC</h3>

<p>When building distributed RPC applications on top of Storm, there are two common patterns that are usually needed. These are encapsulated by <a href="javadocs/org/apache/storm/task/CoordinatedBolt.html">CoordinatedBolt</a> and <a href="javadocs/org/apache/storm/task/KeyedFairBolt.html">KeyedFairBolt</a> which are part of the “standard library” that ships with the Storm codebase.</p>

<p><code class="language-plaintext highlighter-rouge">CoordinatedBolt</code> wraps the bolt containing your logic and figures out when your bolt has received all the tuples for any given request. It makes heavy use of direct streams to do this.</p>

<p><code class="language-plaintext highlighter-rouge">KeyedFairBolt</code> also wraps the bolt containing your logic and makes sure your topology processes multiple DRPC invocations at the same time, instead of doing them serially one at a time.</p>

<p>See <a href="Distributed-RPC.html">Distributed RPC</a> for more details.</p>
