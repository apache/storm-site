<p>This page lists issues people have run into when using Storm along with their solutions.</p>

<h3 id="worker-processes-are-crashing-on-startup-with-no-stack-trace">Worker processes are crashing on startup with no stack trace</h3>

<p>Possible symptoms:</p>

<ul>
  <li>Topologies work with one node, but workers crash with multiple nodes</li>
</ul>

<p>Solutions:</p>

<ul>
  <li>You may have a misconfigured subnet, where nodes can’t locate other nodes based on their hostname. ZeroMQ sometimes crashes the process when it can’t resolve a host. There are two solutions:</li>
  <li>Make a mapping from hostname to IP address in /etc/hosts</li>
  <li>Set up an internal DNS so that nodes can locate each other based on hostname.</li>
</ul>

<h3 id="nodes-are-unable-to-communicate-with-each-other">Nodes are unable to communicate with each other</h3>

<p>Possible symptoms:</p>

<ul>
  <li>Every spout tuple is failing</li>
  <li>Processing is not working</li>
</ul>

<p>Solutions:</p>

<ul>
  <li>Storm doesn’t work with ipv6. You can force ipv4 by adding <code class="language-plaintext highlighter-rouge">-Djava.net.preferIPv4Stack=true</code> to the supervisor child options and restarting the supervisor.</li>
  <li>You may have a misconfigured subnet. See the solutions for <code class="language-plaintext highlighter-rouge">Worker processes are crashing on startup with no stack trace</code></li>
</ul>

<h3 id="topology-stops-processing-tuples-after-awhile">Topology stops processing tuples after awhile</h3>

<p>Symptoms:</p>

<ul>
  <li>Processing works fine for a while, and then suddenly stops and spout tuples start failing en masse.</li>
</ul>

<p>Solutions:</p>

<ul>
  <li>This is a known issue with ZeroMQ 2.1.10. Downgrade to ZeroMQ 2.1.7.</li>
</ul>

<h3 id="not-all-supervisors-appear-in-storm-ui">Not all supervisors appear in Storm UI</h3>

<p>Symptoms:</p>

<ul>
  <li>Some supervisor processes are missing from the Storm UI</li>
  <li>List of supervisors in Storm UI changes on refreshes</li>
</ul>

<p>Solutions:</p>

<ul>
  <li>Make sure the supervisor local dirs are independent (e.g., not sharing a local dir over NFS)</li>
  <li>Try deleting the local dirs for the supervisors and restarting the daemons. Supervisors create a unique id for themselves and store it locally. When that id is copied to other nodes, Storm gets confused.</li>
</ul>

<h3 id="multiple-defaultsyaml-found-error">“Multiple defaults.yaml found” error</h3>

<p>Symptoms:</p>

<ul>
  <li>When deploying a topology with “storm jar”, you get this error</li>
</ul>

<p>Solution:</p>

<ul>
  <li>You’re most likely including the Storm jars inside your topology jar. When packaging your topology jar, don’t include the Storm jars as Storm will put those on the classpath for you.</li>
</ul>

<h3 id="nosuchmethoderror-when-running-storm-jar">“NoSuchMethodError” when running storm jar</h3>

<p>Symptoms:</p>

<ul>
  <li>When running storm jar, you get a cryptic “NoSuchMethodError”</li>
</ul>

<p>Solution:</p>

<ul>
  <li>You’re deploying your topology with a different version of Storm than you built your topology against. Make sure the storm client you use comes from the same version as the version you compiled your topology against.</li>
</ul>

<h3 id="kryo-concurrentmodificationexception">Kryo ConcurrentModificationException</h3>

<p>Symptoms:</p>

<ul>
  <li>At runtime, you get a stack trace like the following:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java.lang.RuntimeException: java.util.ConcurrentModificationException
	at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:84)
	at org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:55)
	at org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:56)
	at org.apache.storm.disruptor$consume_loop_STAR_$fn__1597.invoke(disruptor.clj:67)
	at org.apache.storm.util$async_loop$fn__465.invoke(util.clj:377)
	at clojure.lang.AFn.run(AFn.java:24)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.util.ConcurrentModificationException
	at java.util.LinkedHashMap$LinkedHashIterator.nextEntry(LinkedHashMap.java:390)
	at java.util.LinkedHashMap$EntryIterator.next(LinkedHashMap.java:409)
	at java.util.LinkedHashMap$EntryIterator.next(LinkedHashMap.java:408)
	at java.util.HashMap.writeObject(HashMap.java:1016)
	at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:959)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1480)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1416)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:346)
	at org.apache.storm.serialization.SerializableSerializer.write(SerializableSerializer.java:21)
	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:554)
	at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:77)
	at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:18)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:472)
	at org.apache.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:27)
</code></pre></div></div>

<p>Solution:</p>

<ul>
  <li>This means that you’re emitting a mutable object as an output tuple. Everything you emit into the output collector must be immutable. What’s happening is that your bolt is modifying the object while it is being serialized to be sent over the network.</li>
</ul>

<h3 id="nimbus-jvm-shuts-down-right-after-start-up">Nimbus JVM shuts down right after start up</h3>

<p>Symptoms:</p>

<ul>
  <li>When starting storm nimbus, it shuts down straight away with only this logged:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2024-01-05 18:54:20.404 [o.a.s.v.ConfigValidation] INFO: Will use [class org.apache.storm.DaemonConfig, class org.apache.storm.Config] for validation
2024-01-05 18:54:20.556 [o.a.s.z.AclEnforcement] INFO: SECURITY IS DISABLED NO FURTHER CHECKS...
2024-01-05 18:54:20.740 [o.a.s.m.r.RocksDbStore] INFO: Opening RocksDB from &lt;your-storm-folder&gt;/storm_rocks, storm.metricstore.rocksdb.create_if_missing=true
</code></pre></div></div>

<ul>
  <li>And the JVM exits with an “EXCEPTION_ILLEGAL_INSTRUCTION” like this:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#
# A fatal error has been detected by the Java Runtime Environment:
#
#  EXCEPTION_ILLEGAL_INSTRUCTION (0xc000001d) at pc=0x00007ff94dc7a56d, pid=12728, tid=0x0000000000001d94
#
# JRE version: OpenJDK Runtime Environment (8.0_232) (build 1.8.0_232-09)
# Java VM: OpenJDK 64-Bit Server VM (25.232-b09 mixed mode windows-amd64 compressed oops)
# Problematic frame:
# C  [librocksdbjni4887247215762585789.dll+0x53a56d]
</code></pre></div></div>

<ul>
  <li>And you’re running on a pre-Haswell Intel or pre-Excavator AMD CPU.</li>
</ul>

<p>Solution:</p>

<ul>
  <li>rocksdb-jni from MVN Repository since version 7.0.4 is built for modern CPUs to take advantage of <a href="https://en.wikipedia.org/wiki/X86_Bit_manipulation_instruction_set#BMI2_(Bit_Manipulation_Instruction_Set_2)">newer instructions</a> for improved performance. Downgrade to version 6.29.5 to resolve this issue.</li>
  <li>Alternatively, recompile rocksdb-jni with PORTABLE=1 as mentioned in the <a href="https://github.com/facebook/rocksdb/blob/master/INSTALL.md">INSTALL.md</a> link in “Compliing from Source” section of https://github.com/facebook/rocksdb/wiki/RocksJava-Basics.</li>
</ul>
