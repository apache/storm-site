<h2 id="deprecated">Deprecated</h2>
<p>Storm-kafka has been deprecated and will be removed in a future Storm release. Please upgrade to storm-kafka-client.
If you need to migrate the committed offsets to the new spout, consider using the storm-kafka-migration tool.</p>

<p>Provides core Storm and Trident spout implementations for consuming data from Apache Kafka 0.8.x.</p>

<p>##Spouts
We support both Trident and core Storm spouts. For both spout implementations, we use a BrokerHost interface that
tracks Kafka broker host to partition mapping and kafkaConfig that controls some Kafka related parameters.</p>

<p>###BrokerHosts
In order to initialize your Kafka spout/emitter you need to construct an instance of the marker interface BrokerHosts.
Currently, we support the following two implementations:</p>

<p>####ZkHosts
ZkHosts is what you should use if you want to dynamically track Kafka broker to partition mapping. This class uses
Kafka’s ZooKeeper entries to track brokerHost -&gt; partition mapping. You can instantiate an object by calling</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="nf">ZkHosts</span><span class="o">(</span><span class="nc">String</span> <span class="n">brokerZkStr</span><span class="o">,</span> <span class="nc">String</span> <span class="n">brokerZkPath</span><span class="o">)</span>
<span class="kd">public</span> <span class="nf">ZkHosts</span><span class="o">(</span><span class="nc">String</span> <span class="n">brokerZkStr</span><span class="o">)</span>
</code></pre></div></div>

<p>Where brokerZkStr is just ip:port (e.g. localhost:2181). brokerZkPath is the root directory under which all the topics and
partition information is stored. By default this is /brokers which is what the default Kafka implementation uses.</p>

<p>By default, the broker-partition mapping is refreshed every 60 seconds from ZooKeeper. If you want to change it, you
should set host.refreshFreqSecs to your chosen value.</p>

<p>####StaticHosts
This is an alternative implementation where broker -&gt; partition information is static. In order to construct an instance
of this class, you need to first construct an instance of GlobalPartitionInformation.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">Broker</span> <span class="n">brokerForPartition0</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Broker</span><span class="o">(</span><span class="s">"localhost"</span><span class="o">);</span><span class="c1">//localhost:9092</span>
<span class="nc">Broker</span> <span class="n">brokerForPartition1</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Broker</span><span class="o">(</span><span class="s">"localhost"</span><span class="o">,</span> <span class="mi">9092</span><span class="o">);</span><span class="c1">//localhost:9092 but we specified the port explicitly</span>
<span class="nc">Broker</span> <span class="n">brokerForPartition2</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Broker</span><span class="o">(</span><span class="s">"localhost:9092"</span><span class="o">);</span><span class="c1">//localhost:9092 specified as one string.</span>
<span class="nc">GlobalPartitionInformation</span> <span class="n">partitionInfo</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">GlobalPartitionInformation</span><span class="o">();</span>
<span class="n">partitionInfo</span><span class="o">.</span><span class="na">addPartition</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">brokerForPartition0</span><span class="o">);</span><span class="c1">//mapping from partition 0 to brokerForPartition0</span>
<span class="n">partitionInfo</span><span class="o">.</span><span class="na">addPartition</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">brokerForPartition1</span><span class="o">);</span><span class="c1">//mapping from partition 1 to brokerForPartition1</span>
<span class="n">partitionInfo</span><span class="o">.</span><span class="na">addPartition</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">brokerForPartition2</span><span class="o">);</span><span class="c1">//mapping from partition 2 to brokerForPartition2</span>
<span class="nc">StaticHosts</span> <span class="n">hosts</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">StaticHosts</span><span class="o">(</span><span class="n">partitionInfo</span><span class="o">);</span>
</code></pre></div></div>

<p>###KafkaConfig
The second thing needed for constructing a kafkaSpout is an instance of KafkaConfig.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="nf">KafkaConfig</span><span class="o">(</span><span class="nc">BrokerHosts</span> <span class="n">hosts</span><span class="o">,</span> <span class="nc">String</span> <span class="n">topic</span><span class="o">)</span>
<span class="kd">public</span> <span class="nf">KafkaConfig</span><span class="o">(</span><span class="nc">BrokerHosts</span> <span class="n">hosts</span><span class="o">,</span> <span class="nc">String</span> <span class="n">topic</span><span class="o">,</span> <span class="nc">String</span> <span class="n">clientId</span><span class="o">)</span>
</code></pre></div></div>

<p>The BrokerHosts can be any implementation of BrokerHosts interface as described above. The topic is name of Kafka topic.
The optional ClientId is used as a part of the ZooKeeper path where the spout’s current consumption offset is stored.</p>

<p>There are 2 extensions of KafkaConfig currently in use.</p>

<p>SpoutConfig is an extension of KafkaConfig that supports additional fields with ZooKeeper connection info and for controlling
behavior specific to KafkaSpout.
The clientId will be used to identify requests which are made using the Kafka Protocol.
The zkRoot will be used as root to store your consumer’s offset.
The id should uniquely identify your spout.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="nf">SpoutConfig</span><span class="o">(</span><span class="nc">BrokerHosts</span> <span class="n">hosts</span><span class="o">,</span> <span class="nc">String</span> <span class="n">topic</span><span class="o">,</span> <span class="nc">String</span> <span class="n">clientId</span><span class="o">,</span> <span class="nc">String</span> <span class="n">zkRoot</span><span class="o">,</span> <span class="nc">String</span> <span class="n">id</span><span class="o">);</span>
<span class="kd">public</span> <span class="nf">SpoutConfig</span><span class="o">(</span><span class="nc">BrokerHosts</span> <span class="n">hosts</span><span class="o">,</span> <span class="nc">String</span> <span class="n">topic</span><span class="o">,</span> <span class="nc">String</span> <span class="n">zkRoot</span><span class="o">,</span> <span class="nc">String</span> <span class="n">id</span><span class="o">);</span>
<span class="kd">public</span> <span class="nf">SpoutConfig</span><span class="o">(</span><span class="nc">BrokerHosts</span> <span class="n">hosts</span><span class="o">,</span> <span class="nc">String</span> <span class="n">topic</span><span class="o">,</span> <span class="nc">String</span> <span class="n">id</span><span class="o">);</span>
</code></pre></div></div>

<p>In addition to these parameters, SpoutConfig contains the following fields that control how KafkaSpout behaves:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// setting for how often to save the current Kafka offset to ZooKeeper</span>
<span class="kd">public</span> <span class="kt">long</span> <span class="n">stateUpdateIntervalMs</span> <span class="o">=</span> <span class="mi">2000</span><span class="o">;</span>

<span class="c1">// Retry strategy for failed messages</span>
<span class="kd">public</span> <span class="nc">String</span> <span class="n">failedMsgRetryManagerClass</span> <span class="o">=</span> <span class="nc">ExponentialBackoffMsgRetryManager</span><span class="o">.</span><span class="na">class</span><span class="o">.</span><span class="na">getName</span><span class="o">();</span>

<span class="c1">// Exponential back-off retry settings.  These are used by ExponentialBackoffMsgRetryManager for retrying messages after a bolt</span>
<span class="c1">// calls OutputCollector.fail(). These come into effect only if ExponentialBackoffMsgRetryManager is being used.</span>
<span class="c1">// Initial delay between successive retries</span>
<span class="kd">public</span> <span class="kt">long</span> <span class="n">retryInitialDelayMs</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
<span class="kd">public</span> <span class="kt">double</span> <span class="n">retryDelayMultiplier</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">;</span>

<span class="c1">// Maximum delay between successive retries    </span>
<span class="kd">public</span> <span class="kt">long</span> <span class="n">retryDelayMaxMs</span> <span class="o">=</span> <span class="mi">60</span> <span class="o">*</span> <span class="mi">1000</span><span class="o">;</span>
<span class="c1">// Failed message will be retried infinitely if retryLimit is less than zero. </span>
<span class="kd">public</span> <span class="kt">int</span> <span class="n">retryLimit</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">;</span>     
</code></pre></div></div>

<p>Core KafkaSpout only accepts an instance of SpoutConfig.</p>

<p>TridentKafkaConfig is another extension of KafkaConfig.
TridentKafkaEmitter only accepts TridentKafkaConfig.</p>

<p>The KafkaConfig class also has bunch of public variables that controls your application’s behavior. Here are defaults:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kt">int</span> <span class="n">fetchSizeBytes</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="o">;</span>
<span class="kd">public</span> <span class="kt">int</span> <span class="n">socketTimeoutMs</span> <span class="o">=</span> <span class="mi">10000</span><span class="o">;</span>
<span class="kd">public</span> <span class="kt">int</span> <span class="n">fetchMaxWait</span> <span class="o">=</span> <span class="mi">10000</span><span class="o">;</span>
<span class="kd">public</span> <span class="kt">int</span> <span class="n">bufferSizeBytes</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="o">;</span>
<span class="kd">public</span> <span class="nc">MultiScheme</span> <span class="n">scheme</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">RawMultiScheme</span><span class="o">();</span>
<span class="kd">public</span> <span class="kt">boolean</span> <span class="n">ignoreZkOffsets</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
<span class="kd">public</span> <span class="kt">long</span> <span class="n">startOffsetTime</span> <span class="o">=</span> <span class="n">kafka</span><span class="o">.</span><span class="na">api</span><span class="o">.</span><span class="na">OffsetRequest</span><span class="o">.</span><span class="na">EarliestTime</span><span class="o">();</span>
<span class="kd">public</span> <span class="kt">long</span> <span class="n">maxOffsetBehind</span> <span class="o">=</span> <span class="nc">Long</span><span class="o">.</span><span class="na">MAX_VALUE</span><span class="o">;</span>
<span class="kd">public</span> <span class="kt">boolean</span> <span class="n">useStartOffsetTimeIfOffsetOutOfRange</span> <span class="o">=</span> <span class="kc">true</span><span class="o">;</span>
<span class="kd">public</span> <span class="kt">int</span> <span class="n">metricsTimeBucketSizeInSecs</span> <span class="o">=</span> <span class="mi">60</span><span class="o">;</span>
</code></pre></div></div>

<p>Most of them are self explanatory except MultiScheme.
###MultiScheme
MultiScheme is an interface that dictates how the ByteBuffer consumed from Kafka gets transformed into a storm tuple. It
also controls the naming of your output field.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="nc">Iterable</span><span class="o">&lt;</span><span class="nc">List</span><span class="o">&lt;</span><span class="nc">Object</span><span class="o">&gt;&gt;</span> <span class="nf">deserialize</span><span class="o">(</span><span class="nc">ByteBuffer</span> <span class="n">ser</span><span class="o">);</span>
<span class="kd">public</span> <span class="nc">Fields</span> <span class="nf">getOutputFields</span><span class="o">();</span>
</code></pre></div></div>

<p>The default <code class="language-plaintext highlighter-rouge">RawMultiScheme</code> just takes the <code class="language-plaintext highlighter-rouge">ByteBuffer</code> and returns a tuple with the ByteBuffer converted to a <code class="language-plaintext highlighter-rouge">byte[]</code>. The name of the outputField is “bytes”. There are alternative implementations like <code class="language-plaintext highlighter-rouge">SchemeAsMultiScheme</code> and <code class="language-plaintext highlighter-rouge">KeyValueSchemeAsMultiScheme</code> which can convert the <code class="language-plaintext highlighter-rouge">ByteBuffer</code> to <code class="language-plaintext highlighter-rouge">String</code>.</p>

<p>There is also an extension of <code class="language-plaintext highlighter-rouge">SchemeAsMultiScheme</code>, <code class="language-plaintext highlighter-rouge">MessageMetadataSchemeAsMultiScheme</code>,
which has an additional deserialize method that accepts the message <code class="language-plaintext highlighter-rouge">ByteBuffer</code> in addition to the <code class="language-plaintext highlighter-rouge">Partition</code> and <code class="language-plaintext highlighter-rouge">offset</code> associated with the message.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="nc">Iterable</span><span class="o">&lt;</span><span class="nc">List</span><span class="o">&lt;</span><span class="nc">Object</span><span class="o">&gt;&gt;</span> <span class="nf">deserializeMessageWithMetadata</span><span class="o">(</span><span class="nc">ByteBuffer</span> <span class="n">message</span><span class="o">,</span> <span class="nc">Partition</span> <span class="n">partition</span><span class="o">,</span> <span class="kt">long</span> <span class="n">offset</span><span class="o">)</span>
</code></pre></div></div>

<p>This is useful for auditing/replaying messages from arbitrary points on a Kafka topic, saving the partition and offset of each message of a discrete stream instead of persisting the entire message.</p>

<p>###Failed message retry
FailedMsgRetryManager is an interface which defines the retry strategy for a failed message. Default implementation is ExponentialBackoffMsgRetryManager which retries with exponential delays
between consecutive retries. To use a custom implementation, set SpoutConfig.failedMsgRetryManagerClass to the full classname
of implementation. Here is the interface</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c1">// Spout initialization can go here. This can be called multiple times during lifecycle of a worker. </span>
    <span class="kt">void</span> <span class="nf">prepare</span><span class="o">(</span><span class="nc">SpoutConfig</span> <span class="n">spoutConfig</span><span class="o">,</span> <span class="nc">Map</span> <span class="n">stormConf</span><span class="o">);</span>

    <span class="c1">// Message corresponding to offset has failed. This method is called only if retryFurther returns true for offset.</span>
    <span class="kt">void</span> <span class="nf">failed</span><span class="o">(</span><span class="nc">Long</span> <span class="n">offset</span><span class="o">);</span>

    <span class="c1">// Message corresponding to offset has been acked.  </span>
    <span class="kt">void</span> <span class="nf">acked</span><span class="o">(</span><span class="nc">Long</span> <span class="n">offset</span><span class="o">);</span>

    <span class="c1">// Message corresponding to the offset, has been re-emitted and under transit.</span>
    <span class="kt">void</span> <span class="nf">retryStarted</span><span class="o">(</span><span class="nc">Long</span> <span class="n">offset</span><span class="o">);</span>

    <span class="cm">/**
     * The offset of message, which is to be re-emitted. Spout will fetch messages starting from this offset
     * and resend them, except completed messages.
     */</span>
    <span class="nc">Long</span> <span class="nf">nextFailedMessageToRetry</span><span class="o">();</span>

    <span class="cm">/**
     * @return True if the message corresponding to the offset should be emitted NOW. False otherwise.
     */</span>
    <span class="kt">boolean</span> <span class="nf">shouldReEmitMsg</span><span class="o">(</span><span class="nc">Long</span> <span class="n">offset</span><span class="o">);</span>

    <span class="cm">/**
     * Spout will clean up the state for this offset if false is returned. If retryFurther is set to true,
     * spout will called failed(offset) in next call and acked(offset) otherwise 
     */</span>
    <span class="kt">boolean</span> <span class="nf">retryFurther</span><span class="o">(</span><span class="nc">Long</span> <span class="n">offset</span><span class="o">);</span>

    <span class="cm">/**
     * Clear any offsets before kafkaOffset. These offsets are no longer available in kafka.
     */</span>
    <span class="nc">Set</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">&gt;</span> <span class="nf">clearOffsetsBefore</span><span class="o">(</span><span class="nc">Long</span> <span class="n">kafkaOffset</span><span class="o">);</span>
</code></pre></div></div>

<h4 id="version-incompatibility">Version incompatibility</h4>
<p>In Storm versions prior to 1.0, the MultiScheme methods accepted a <code class="language-plaintext highlighter-rouge">byte[]</code> instead of <code class="language-plaintext highlighter-rouge">ByteBuffer</code>. The <code class="language-plaintext highlighter-rouge">MultScheme</code> and the related
Scheme apis were changed in version 1.0 to accept a ByteBuffer instead of a byte[].</p>

<p>This means that pre 1.0 kafka spouts will not work with Storm versions 1.0 and higher. While running topologies in Storm version 1.0
and higher, it must be ensured that the storm-kafka version is at least 1.0. Pre 1.0 shaded topology jars that bundles
storm-kafka classes must be rebuilt with storm-kafka version 1.0 for running in clusters with storm 1.0 and higher.</p>

<h3 id="examples">Examples</h3>

<h4 id="core-spout">Core Spout</h4>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">BrokerHosts</span> <span class="n">hosts</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ZkHosts</span><span class="o">(</span><span class="n">zkConnString</span><span class="o">);</span>
<span class="nc">SpoutConfig</span> <span class="n">spoutConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">SpoutConfig</span><span class="o">(</span><span class="n">hosts</span><span class="o">,</span> <span class="n">topicName</span><span class="o">,</span> <span class="s">"/"</span> <span class="o">+</span> <span class="n">topicName</span><span class="o">,</span> <span class="no">UUID</span><span class="o">.</span><span class="na">randomUUID</span><span class="o">().</span><span class="na">toString</span><span class="o">());</span>
<span class="n">spoutConfig</span><span class="o">.</span><span class="na">scheme</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">SchemeAsMultiScheme</span><span class="o">(</span><span class="k">new</span> <span class="nc">StringScheme</span><span class="o">());</span>
<span class="nc">KafkaSpout</span> <span class="n">kafkaSpout</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">KafkaSpout</span><span class="o">(</span><span class="n">spoutConfig</span><span class="o">);</span>
</code></pre></div></div>

<h4 id="trident-spout">Trident Spout</h4>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">TridentTopology</span> <span class="n">topology</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">TridentTopology</span><span class="o">();</span>
<span class="nc">BrokerHosts</span> <span class="n">zk</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ZkHosts</span><span class="o">(</span><span class="s">"localhost"</span><span class="o">);</span>
<span class="nc">TridentKafkaConfig</span> <span class="n">spoutConf</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">TridentKafkaConfig</span><span class="o">(</span><span class="n">zk</span><span class="o">,</span> <span class="s">"test-topic"</span><span class="o">);</span>
<span class="n">spoutConf</span><span class="o">.</span><span class="na">scheme</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">SchemeAsMultiScheme</span><span class="o">(</span><span class="k">new</span> <span class="nc">StringScheme</span><span class="o">());</span>
<span class="nc">OpaqueTridentKafkaSpout</span> <span class="n">spout</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">OpaqueTridentKafkaSpout</span><span class="o">(</span><span class="n">spoutConf</span><span class="o">);</span>
</code></pre></div></div>

<h3 id="how-kafkaspout-stores-offsets-of-a-kafka-topic-and-recovers-in-case-of-failures">How KafkaSpout stores offsets of a Kafka topic and recovers in case of failures</h3>

<p>As shown in the above KafkaConfig properties, you can control from where in the Kafka topic the spout begins to read by
setting <code class="language-plaintext highlighter-rouge">KafkaConfig.startOffsetTime</code> as follows:</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">kafka.api.OffsetRequest.EarliestTime()</code>:  read from the beginning of the topic (i.e. from the oldest messages onwards)</li>
  <li><code class="language-plaintext highlighter-rouge">kafka.api.OffsetRequest.LatestTime()</code>: read from the end of the topic (i.e. any new messsages that are being written to the topic)</li>
  <li>A Unix timestamp aka seconds since the epoch (e.g. via <code class="language-plaintext highlighter-rouge">System.currentTimeMillis()</code>):
see <a href="https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-HowdoIaccuratelygetoffsetsofmessagesforacertaintimestampusingOffsetRequest?">How do I accurately get offsets of messages for a certain timestamp using OffsetRequest?</a> in the Kafka FAQ</li>
</ol>

<p>As the topology runs the Kafka spout keeps track of the offsets it has read and emitted by storing state information
under the ZooKeeper path <code class="language-plaintext highlighter-rouge">SpoutConfig.zkRoot+ "/" + SpoutConfig.id</code>.  In the case of failures it recovers from the last
written offset in ZooKeeper.</p>

<blockquote>
  <p><strong>Important:</strong>  When re-deploying a topology make sure that the settings for <code class="language-plaintext highlighter-rouge">SpoutConfig.zkRoot</code> and <code class="language-plaintext highlighter-rouge">SpoutConfig.id</code>
were not modified, otherwise the spout will not be able to read its previous consumer state information (i.e. the
offsets) from ZooKeeper – which may lead to unexpected behavior and/or to data loss, depending on your use case.</p>
</blockquote>

<p>This means that when a topology has run once the setting <code class="language-plaintext highlighter-rouge">KafkaConfig.startOffsetTime</code> will not have an effect for
subsequent runs of the topology because now the topology will rely on the consumer state information (offsets) in
ZooKeeper to determine from where it should begin (more precisely: resume) reading.
If you want to force the spout to ignore any consumer state information stored in ZooKeeper, then you should
set the parameter <code class="language-plaintext highlighter-rouge">KafkaConfig.ignoreZkOffsets</code> to <code class="language-plaintext highlighter-rouge">true</code>.  If <code class="language-plaintext highlighter-rouge">true</code>, the spout will always begin reading from the
offset defined by <code class="language-plaintext highlighter-rouge">KafkaConfig.startOffsetTime</code> as described above.</p>

<h2 id="using-storm-kafka-with-different-versions-of-kafka">Using storm-kafka with different versions of Kafka</h2>

<p>Storm-kafka’s Kafka dependency is defined as <code class="language-plaintext highlighter-rouge">provided</code> scope in maven, meaning it will not be pulled in
as a transitive dependency. This allows you to use a version of Kafka dependency-compatible with your Kafka cluster.</p>

<p>When building a project with storm-kafka, you must explicitly add the Kafka dependency. For example, to
use Kafka 0.8.1.1 built against Scala 2.10, you would use the following dependency in your <code class="language-plaintext highlighter-rouge">pom.xml</code>:</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>org.apache.kafka<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>kafka_2.10<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;version&gt;</span>0.8.1.1<span class="nt">&lt;/version&gt;</span>
    <span class="nt">&lt;exclusions&gt;</span>
        <span class="nt">&lt;exclusion&gt;</span>
            <span class="nt">&lt;groupId&gt;</span>org.apache.zookeeper<span class="nt">&lt;/groupId&gt;</span>
            <span class="nt">&lt;artifactId&gt;</span>zookeeper<span class="nt">&lt;/artifactId&gt;</span>
        <span class="nt">&lt;/exclusion&gt;</span>
        <span class="nt">&lt;exclusion&gt;</span>
            <span class="nt">&lt;groupId&gt;</span>log4j<span class="nt">&lt;/groupId&gt;</span>
            <span class="nt">&lt;artifactId&gt;</span>log4j<span class="nt">&lt;/artifactId&gt;</span>
        <span class="nt">&lt;/exclusion&gt;</span>
    <span class="nt">&lt;/exclusions&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div></div>

<p>Note that the ZooKeeper and log4j dependencies are excluded to prevent version conflicts with Storm’s dependencies.</p>

<p>You can also override the kafka dependency version while building from maven, with parameter <code class="language-plaintext highlighter-rouge">storm.kafka.version</code> and <code class="language-plaintext highlighter-rouge">storm.kafka.artifact.id</code>
e.g. <code class="language-plaintext highlighter-rouge">mvn clean install -Dstorm.kafka.artifact.id=kafka_2.11 -Dstorm.kafka.version=0.9.0.1</code></p>

<p>When selecting a kafka dependency version, you should ensure -</p>

<ol>
  <li>kafka api is compatible with storm-kafka. Currently, only 0.9.x and 0.8.x client API is supported by storm-kafka 
module. If you want to use a higher version, storm-kafka-client module should be used instead.</li>
  <li>The kafka client selected by you should be wire compatible with the broker. e.g. 0.9.x client will not work with 
0.8.x broker.</li>
</ol>

<p>##Writing to Kafka as part of your topology
You can create an instance of org.apache.storm.kafka.bolt.KafkaBolt and attach it as a component to your topology or if you
are using trident you can use org.apache.storm.kafka.trident.TridentState, org.apache.storm.kafka.trident.TridentStateFactory and
org.apache.storm.kafka.trident.TridentKafkaUpdater.</p>

<p>You need to provide implementation of following 2 interfaces</p>

<p>###TupleToKafkaMapper and TridentTupleToKafkaMapper
These interfaces have 2 methods defined:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="no">K</span> <span class="nf">getKeyFromTuple</span><span class="o">(</span><span class="nc">Tuple</span><span class="o">/</span><span class="nc">TridentTuple</span> <span class="n">tuple</span><span class="o">);</span>
<span class="no">V</span> <span class="nf">getMessageFromTuple</span><span class="o">(</span><span class="nc">Tuple</span><span class="o">/</span><span class="nc">TridentTuple</span> <span class="n">tuple</span><span class="o">);</span>
</code></pre></div></div>

<p>As the name suggests, these methods are called to map a tuple to Kafka key and Kafka message. If you just want one field
as key and one field as value, then you can use the provided FieldNameBasedTupleToKafkaMapper.java
implementation. In the KafkaBolt, the implementation always looks for a field with field name “key” and “message” if you
use the default constructor to construct FieldNameBasedTupleToKafkaMapper for backward compatibility
reasons. Alternatively you could also specify a different key and message field by using the non default constructor.
In the TridentKafkaState you must specify what is the field name for key and message as there is no default constructor.
These should be specified while constructing and instance of FieldNameBasedTupleToKafkaMapper.</p>

<p>###KafkaTopicSelector and trident KafkaTopicSelector
This interface has only one method</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">interface</span> <span class="nc">KafkaTopicSelector</span> <span class="o">{</span>
    <span class="nc">String</span> <span class="nf">getTopics</span><span class="o">(</span><span class="nc">Tuple</span><span class="o">/</span><span class="nc">TridentTuple</span> <span class="n">tuple</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>
<p>The implementation of this interface should return the topic to which the tuple’s key/message mapping needs to be published
You can return a null and the message will be ignored. If you have one static topic name then you can use
DefaultTopicSelector.java and set the name of the topic in the constructor.
<code class="language-plaintext highlighter-rouge">FieldNameTopicSelector</code> and <code class="language-plaintext highlighter-rouge">FieldIndexTopicSelector</code> use to support decided which topic should to push message from tuple.
User could specify the field name or field index in tuple ,selector will use this value as topic name which to publish message.
When the topic name not found , <code class="language-plaintext highlighter-rouge">KafkaBolt</code> will write messages into default topic .
Please make sure the default topic have created .</p>

<h3 id="specifying-kafka-producer-properties">Specifying Kafka producer properties</h3>
<p>You can provide all the produce properties in your Storm topology by calling <code class="language-plaintext highlighter-rouge">KafkaBolt.withProducerProperties()</code> and <code class="language-plaintext highlighter-rouge">TridentKafkaStateFactory.withProducerProperties()</code>. Please see  http://kafka.apache.org/documentation.html#newproducerconfigs
Section “Important configuration properties for the producer” for more details.</p>

<p>###Using wildcard kafka topic match
You can do a wildcard topic match by adding the following config</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">Config</span> <span class="n">config</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Config</span><span class="o">();</span>
<span class="n">config</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"kafka.topic.wildcard.match"</span><span class="o">,</span><span class="kc">true</span><span class="o">);</span>
</code></pre></div></div>

<p>After this you can specify a wildcard topic for matching e.g. clickstream.*.log.  This will match all streams matching clickstream.my.log, clickstream.cart.log etc</p>

<p>###Putting it all together</p>

<p>For the bolt :</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">TopologyBuilder</span> <span class="n">builder</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">TopologyBuilder</span><span class="o">();</span>

<span class="nc">Fields</span> <span class="n">fields</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Fields</span><span class="o">(</span><span class="s">"key"</span><span class="o">,</span> <span class="s">"message"</span><span class="o">);</span>
<span class="nc">FixedBatchSpout</span> <span class="n">spout</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">FixedBatchSpout</span><span class="o">(</span><span class="n">fields</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span>
            <span class="k">new</span> <span class="nf">Values</span><span class="o">(</span><span class="s">"storm"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">),</span>
            <span class="k">new</span> <span class="nf">Values</span><span class="o">(</span><span class="s">"trident"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">),</span>
            <span class="k">new</span> <span class="nf">Values</span><span class="o">(</span><span class="s">"needs"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">),</span>
            <span class="k">new</span> <span class="nf">Values</span><span class="o">(</span><span class="s">"javadoc"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">spout</span><span class="o">.</span><span class="na">setCycle</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>
<span class="n">builder</span><span class="o">.</span><span class="na">setSpout</span><span class="o">(</span><span class="s">"spout"</span><span class="o">,</span> <span class="n">spout</span><span class="o">,</span> <span class="mi">5</span><span class="o">);</span>
<span class="c1">//set producer properties.</span>
<span class="nc">Properties</span> <span class="n">props</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>
<span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"bootstrap.servers"</span><span class="o">,</span> <span class="s">"localhost:9092"</span><span class="o">);</span>
<span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"acks"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">);</span>
<span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"key.serializer"</span><span class="o">,</span> <span class="s">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="o">);</span>
<span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"value.serializer"</span><span class="o">,</span> <span class="s">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="o">);</span>

<span class="nc">KafkaBolt</span> <span class="n">bolt</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">KafkaBolt</span><span class="o">()</span>
        <span class="o">.</span><span class="na">withProducerProperties</span><span class="o">(</span><span class="n">props</span><span class="o">)</span>
        <span class="o">.</span><span class="na">withTopicSelector</span><span class="o">(</span><span class="k">new</span> <span class="nc">DefaultTopicSelector</span><span class="o">(</span><span class="s">"test"</span><span class="o">))</span>
        <span class="o">.</span><span class="na">withTupleToKafkaMapper</span><span class="o">(</span><span class="k">new</span> <span class="nc">FieldNameBasedTupleToKafkaMapper</span><span class="o">());</span>
<span class="n">builder</span><span class="o">.</span><span class="na">setBolt</span><span class="o">(</span><span class="s">"forwardToKafka"</span><span class="o">,</span> <span class="n">bolt</span><span class="o">,</span> <span class="mi">8</span><span class="o">).</span><span class="na">shuffleGrouping</span><span class="o">(</span><span class="s">"spout"</span><span class="o">);</span>

<span class="nc">Config</span> <span class="n">conf</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Config</span><span class="o">();</span>

<span class="nc">StormSubmitter</span><span class="o">.</span><span class="na">submitTopology</span><span class="o">(</span><span class="s">"kafkaboltTest"</span><span class="o">,</span> <span class="n">conf</span><span class="o">,</span> <span class="n">builder</span><span class="o">.</span><span class="na">createTopology</span><span class="o">());</span>
</code></pre></div></div>

<p>For Trident:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">Fields</span> <span class="n">fields</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Fields</span><span class="o">(</span><span class="s">"word"</span><span class="o">,</span> <span class="s">"count"</span><span class="o">);</span>
<span class="nc">FixedBatchSpout</span> <span class="n">spout</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">FixedBatchSpout</span><span class="o">(</span><span class="n">fields</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span>
        <span class="k">new</span> <span class="nf">Values</span><span class="o">(</span><span class="s">"storm"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">),</span>
        <span class="k">new</span> <span class="nf">Values</span><span class="o">(</span><span class="s">"trident"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">),</span>
        <span class="k">new</span> <span class="nf">Values</span><span class="o">(</span><span class="s">"needs"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">),</span>
        <span class="k">new</span> <span class="nf">Values</span><span class="o">(</span><span class="s">"javadoc"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">spout</span><span class="o">.</span><span class="na">setCycle</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>

<span class="nc">TridentTopology</span> <span class="n">topology</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">TridentTopology</span><span class="o">();</span>
<span class="nc">Stream</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">topology</span><span class="o">.</span><span class="na">newStream</span><span class="o">(</span><span class="s">"spout1"</span><span class="o">,</span> <span class="n">spout</span><span class="o">);</span>

<span class="c1">//set producer properties.</span>
<span class="nc">Properties</span> <span class="n">props</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>
<span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"bootstrap.servers"</span><span class="o">,</span> <span class="s">"localhost:9092"</span><span class="o">);</span>
<span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"acks"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">);</span>
<span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"key.serializer"</span><span class="o">,</span> <span class="s">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="o">);</span>
<span class="n">props</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"value.serializer"</span><span class="o">,</span> <span class="s">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="o">);</span>

<span class="nc">TridentKafkaStateFactory</span> <span class="n">stateFactory</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">TridentKafkaStateFactory</span><span class="o">()</span>
        <span class="o">.</span><span class="na">withProducerProperties</span><span class="o">(</span><span class="n">props</span><span class="o">)</span>
        <span class="o">.</span><span class="na">withKafkaTopicSelector</span><span class="o">(</span><span class="k">new</span> <span class="nc">DefaultTopicSelector</span><span class="o">(</span><span class="s">"test"</span><span class="o">))</span>
        <span class="o">.</span><span class="na">withTridentTupleToKafkaMapper</span><span class="o">(</span><span class="k">new</span> <span class="nc">FieldNameBasedTupleToKafkaMapper</span><span class="o">(</span><span class="s">"word"</span><span class="o">,</span> <span class="s">"count"</span><span class="o">));</span>
<span class="n">stream</span><span class="o">.</span><span class="na">partitionPersist</span><span class="o">(</span><span class="n">stateFactory</span><span class="o">,</span> <span class="n">fields</span><span class="o">,</span> <span class="k">new</span> <span class="nc">TridentKafkaUpdater</span><span class="o">(),</span> <span class="k">new</span> <span class="nc">Fields</span><span class="o">());</span>

<span class="nc">Config</span> <span class="n">conf</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Config</span><span class="o">();</span>
<span class="nc">StormSubmitter</span><span class="o">.</span><span class="na">submitTopology</span><span class="o">(</span><span class="s">"kafkaTridentTest"</span><span class="o">,</span> <span class="n">conf</span><span class="o">,</span> <span class="n">topology</span><span class="o">.</span><span class="na">build</span><span class="o">());</span>
</code></pre></div></div>

<h2 id="committer-sponsors">Committer Sponsors</h2>

<ul>
  <li>P. Taylor Goetz (<a href="mailto:ptgoetz@apache.org">ptgoetz@apache.org</a>)</li>
</ul>
